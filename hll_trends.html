<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="https://blog.harterrt.com/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="https://blog.harterrt.com/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="https://blog.harterrt.com/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Ryan T. Harter">
  <meta name="description" content="Posts and writings by Ryan T. Harter">

  <link href="https://blog.harterrt.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="blog.harterrt.com Atom" />
  <link href="https://blog.harterrt.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="blog.harterrt.com RSS" />

<meta name="keywords" content="">

  <title>
    blog.harterrt.com
&ndash; PSA: Don't use approximate counts for trends  </title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-83638505-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="https://blog.harterrt.com">
        <img src="https://www.gravatar.com/avatar/8259d4073ed8ba5f61f5d60c978b0e69" alt="logo" class="round-img">
      </a>
      <h2><a href="https://blog.harterrt.com">Ryan T. Harter</a></h2>
      <p>Principal Data Scientist @ Mozilla</p>
      <ul>
        <li><a href="https://blog.harterrt.com/pages/about.html">About</a></li>
        <li><a href="resume.pdf" target="_blank">Resume</a></li>
        <li><a href="https://github.com/harterrt" target="_blank">Github</a></li>
        <li><a href="https://twitter.com/harterrt" target="_blank">Twitter</a></li>
        <li><a href="http://www.linkedin.com/pub/ryan-harter/11/a24/a21" target="_blank">LinkedIn</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <header>
      <p>
      <a href="https://blog.harterrt.com">Index</a> &brvbar; <a href="https://blog.harterrt.com/archives.html">Archives</a>
      &brvbar; <a href="https://blog.harterrt.com/feeds/all.atom.xml">Atom</a>
      &brvbar; <a href="https://blog.harterrt.com/feeds/all.rss.xml">RSS</a>
      </p>
    </header>

<article>
  <div class="article_title">
    <h1><a href="https://blog.harterrt.com/hll_trends.html">PSA: Don't use approximate counts for trends</a></h1>
  </div>
  <div class="article_text">
    <p>I got caught giving some bad advice this week,
so I decided to share here as penance.
TL;DR: Probabilistic counts are great,
but they shouldn't be used everywhere.</p>
<hr />
<p>Counting stuff is hard.
We use probabilistic algorithms pretty frequently at Mozilla.
For example, when trying to get user counts,
we rely heavily on Presto's 
<a href="https://prestodb.io/docs/current/functions/aggregate.html#approx_distinct">approx_distinct</a>
aggregator.
Roberto's even written a 
<a href="https://github.com/vitillo/presto-hyperloglog">Presto Plugin</a>
and a 
<a href="https://github.com/vitillo/spark-hyperloglog">Spark Package</a>
to allow us to include
<a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a>
variables in datasets like
<a href="https://docs.telemetry.mozilla.org/datasets/batch_view/client_count_daily/reference.html">client_count_daily</a>.</p>
<p>These algorithms save a lot of compute power and analyst time,
but it's important to remember that they do introduce some variance.</p>
<p>In fact, the error bars are substantial.
By default, Presto's <code>approx_distinct</code> is tuned to have a standard error of 2.3%,
which means one out of every three <code>approx_distinct</code> estimates
will be off by more than 2.3%.
I can set a tighter standard error by passing a second parameter,
but it 
<a href="https://prestodb.io/docs/current/functions/aggregate.html#approx_distinct">looks like</a>
I can't request anything below 0.5%.
For our HLL datasets, we set a
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/src/main/scala/com/mozilla/telemetry/views/GenericCountView.scala#L45">default standard error</a>
of 1.63%, which is still significant.</p>
<p>Unfortunately, we can't get the standard error to be much smaller than 1%.
Databricks has
<a href="https://databricks.com/blog/2016/05/19/approximate-algorithms-in-apache-spark-hyperloglog-and-quantiles.html">a writeup here</a>
which explains that the compute time for their probabilistic estimate
starts to be greater than the compute time for an exact count
somewhere between an error of 0.5% and 1.0%.</p>
<p>Most of the time, this isn't an issue.
For example, if I'm trying to count how many clients used a 
<a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/">Container Tab</a>
yesterday I don't care if it's 100mm or 105mm;
those numbers are the same to me.
However, <strong>that noise becomes distracting</strong>
if I'm building a dashboard to track year over year change.</p>
<h2>An example</h2>
<p>I put together an
<a href="https://blog.harterrt.com/images/probabilistic_counts.html">example notebook</a>
to explore a little.
I created a toy dataframe containing
7 days of data and 1000 <code>client_id</code>'s per day.
Then I got an approximate count of the clients for each day.
Here's what an arbitrary set of daily errors look like:</p>
<p><img src="https://blog.harterrt.com/images/probabilistic_count_errors.png"></p>
<p>By default, pyspark's 
<a href="https://spark.apache.org/docs/2.0.2/api/java/org/apache/spark/sql/functions.html#approxCountDistinct(java.lang.String,%20double)">approxCountDistinct</a>
aggregator has a relative standard deviation (<code>rsd</code>) of 5%!
The maximum error magnitude we see in this dataset is 7.5% (day 4).</p>
<p>In my opinion, Spark's documentation obfuscates the real interpretation
of this <code>rsd</code> value, calling it the: "maximum estimation error allowed".
In reality, there is no "maximum error" allowed.
The <code>rsd</code> is a standard deviation for an approximately normal distribution.
Roughly one in three errors are going to be bigger than the <code>rsd</code>.</p>
<p>What's worse is that this graph makes us think there's movement
in this metric over time.
In reality, the user count is perfectly flat at 1000 users every day.
Since these errors aren't correlated over time,
we see big day over day swings in the estimates.
The largest swing occurs from day 6 to day 7 where the user count
jumps by 13.7% (-6.8% to 6.9%)!</p>
<h2>Conclusion</h2>
<p>So what's the take away?
Probabilistic counts are still super useful tools,
but it's important to consider what kind of error they're going to introduce.
In particular, don't use probabilistic counts (like <code>approx_distinct</code>)
when looking at year over year rates or plotting trend lines.</p>
  </div>
  <div class="article_meta">
    <p>Posted on: Tue 24 April 2018</p>
    <p>Category: <a href="https://blog.harterrt.com/category/mozilla.html">mozilla</a>
    </p>
  </div>
  <hr>
  <div class="article_footer">
    <p>
        Feel free to share any feedback via email!
        You can reach me at <code>harterrt</code> on gmail.
        Look forward to hearing from you!
    </p>
  </div>


</article>


    <div id="ending_message">
      <p>&copy; Ryan T. Harter. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. </p>
    </div>
  </main>
</body>
</html>