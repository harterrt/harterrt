<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>blog.harterrt.com</title><link>http://blog.harterrt.com/</link><description></description><lastBuildDate>Thu, 15 Jun 2017 00:00:00 -0700</lastBuildDate><item><title>Bad Tools are Insidious</title><link>http://blog.harterrt.com/bad-tools.html</link><description>&lt;p&gt;This is my first job making data tools that other people use.
In the past, I've always been a data scientist -
a consumer of these tools.
I'm learning a lot.&lt;/p&gt;
&lt;p&gt;Last quarter, I learned that bad tools are often hard to spot even when they're damaging productivity.
I sum this up by saying that &lt;strong&gt;bad tools are insidious&lt;/strong&gt;.
This may be &lt;a href="https://sivers.org/obvious"&gt;obvious to you&lt;/a&gt; but I'm excited by the insight.&lt;/p&gt;
&lt;h2 id="bad-tools-are-hard-to-spot"&gt;Bad tools are hard to spot&lt;/h2&gt;
&lt;p&gt;I spent some time working directly with analysts building ETL jobs.
I found some big usability gaps with our tools
and I was surprised I wasn't hearing about these problems from our analysts.&lt;/p&gt;
&lt;p&gt;I looked back to previous jobs where I was on the other side of this equation.
I remember being totally engrossed in a problem and excited to finding a solution.
All I wanted were tools good enough to get the job done.
I didn't care to reflect on how I could make the process smoother.
I wanted to explore and interate.&lt;/p&gt;
&lt;p&gt;When I dug into analyses this quarter, I had a different perspective.
I was working with the intention of improving our tools
and the analysis was secondary.
It was much easier to find workflow improvements this way.&lt;/p&gt;
&lt;p&gt;In the &lt;a href="https://en.wikipedia.org/wiki/The_Design_of_Everyday_Things"&gt;Design of Everyday Things&lt;/a&gt; 
Donald notes that users tend to blame themselves when they have difficulty with tools.
That's probably part of the issue here as well.&lt;/p&gt;
&lt;h2 id="bad-tools-hurt"&gt;Bad tools hurt&lt;/h2&gt;
&lt;p&gt;If our users aren't complaining, is it really a problem that needs to get fixed?
I think so.
We all understand that bad tools hurt our productivity.
However, I think we tend to underestimate the value of good tools when we do our mental accounting.&lt;/p&gt;
&lt;p&gt;Say I'm working on a new ETL job that takes ~5 minutes to test by hand
but ~1 minute to test programatically.
By default, I'd value implementing good tests at 4 minutes per test run.&lt;/p&gt;
&lt;p&gt;This is a huge underestimate!
Testing by hand introduces a context shift, another chance to get distracted,
and another chance to fall out of flow.
I'll bet a 5 minute distraction can easily end up costing me 20 minutes of productivity on a good day.&lt;/p&gt;
&lt;p&gt;Your tools should be a joy to use.
The better they work, the easier it is to stay in flow, be creative, and stay excited.&lt;/p&gt;
&lt;h1 id="in-summary"&gt;In Summary&lt;/h1&gt;
&lt;p&gt;Don't expect your users to tell you how to improve your tools.
You're probably going to need to
&lt;a href="https://en.wikipedia.org/wiki/Eating_your_own_dog_food"&gt;eat your own dogfood&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Thu, 15 Jun 2017 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2017-06-15:bad-tools.html</guid></item><item><title>Literature Review: Writing Great Documentation</title><link>http://blog.harterrt.com/lit-review.html</link><description>&lt;div id="preamble"&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;I&amp;#8217;m working on a big overhaul of my team&amp;#8217;s documentation.
I&amp;#8217;ve noticed writing documentation is a difficult thing to get right.
I haven&amp;#8217;t seen any great example for a data product, either.
I don&amp;#8217;t have much experience in this area,
so I decided to review what&amp;#8217;s already been written about creating great documentation.
This is a summary of what I&amp;#8217;ve found,
both for my own reference and to help others understand my thought process.&lt;/p&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_findings"&gt;Findings&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;I should note, all the literature I could find focused on documenting software products.
I am willing to bet that a data product is going to have different documentation needs than most software products.
But, this is as good a place to start as any.&lt;/p&gt;&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_structure_amp_what_to_write"&gt;Structure &amp;amp; What to Write&lt;/h3&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Most seem to agree that a &lt;strong&gt;README&lt;/strong&gt; is a critical piece of documentation.
The README is usually comprised of two key parts:&lt;/p&gt;&lt;/div&gt;
&lt;div class="olist arabic"&gt;&lt;ol class="arabic"&gt;
&lt;li&gt;
&lt;p&gt;
A quick introduction explaining what this project is, why the reader should
  care, and whether it&amp;#8217;s worth investing time to understand it better.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
A simple tutorial to get the reader started and give a feel for what the tool
  actually does.
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;If the reader decides they want to learn more,
there should be a set of &lt;strong&gt;topical guides or tutorials&lt;/strong&gt; which comprise the bulk of the documentation.
Think of each of these guides as a class focused on teaching your student (reader) a single skill.
Reading all of these guides should take "someone who has never seen your product and make them an expert user". [&lt;a href="#TDT"&gt;TDT&lt;/a&gt;]
With that in mind, make sure there&amp;#8217;s some sense of order to these lessons (easy to hard).&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;If your reader gets this far, they are now very comfortable with your product.
From here, they need high-quality &lt;strong&gt;reference material&lt;/strong&gt;.
In my experience, this is the most common documentation provided,
but it is needed latest in the process and only by the most advanced users!&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;When I started this research,
I was having a hard time figuring out how we were going to separate our
prose documentation from our development notes.
Now I see that these are just different stages in this learning process.
First we explain what it is, then how to use it, and finally, how to extend it.&lt;/p&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_style"&gt;Style&lt;/h3&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Most articles suggest adopting a style guide to make it easier for a user to read your documentation.
The writing should pull you through the document and feel natural.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;If you want your documentation to read naturally, you should try to become a better writer.
This comes as cold solace to most folks, since I need my documentation now
and I can&amp;#8217;t wait 10,000 hours to become an expert writer, but it&amp;#8217;s worth mentioning.
The overwhelming consensus is that the best way to become a better writer is to &lt;strong&gt;write a lot&lt;/strong&gt;.
If you want to write great documentation, consider building habits that will make you a great writer.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;As with programming, maintaining a consistent style will help readers understand your documentation naturally.
Note, the important word here is "consistent".
&lt;strong&gt;Choose a style and stick with it&lt;/strong&gt;.
This sounds obvious, but I rarely find corporate documentation with consistent style across tutorials.
Have a style guide and enforce it.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;As you choose your style guide, be aware that most of the advice is focused on physical media.
Your documentation is probably going to be read digitally,
so your readers will have different expectations.
Specifically, readers are going to skim your writing, so make it easy to identify important information.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Use &lt;strong&gt;visual markup&lt;/strong&gt; like bold text, code blocks, call-outs
(e.g &lt;a href="http://www.methods.co.nz/asciidoc/chunked/ch16.html#X22"&gt;1&lt;/a&gt;,
&lt;a href="http://getbootstrap.com/components/#alerts"&gt;2&lt;/a&gt;), and section headers.
Similarly, avoid long paragraphs.
Short paragraphs that describe one concept each makes finding important information easier.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Most guides suggest keeping a &lt;strong&gt;conversational tone&lt;/strong&gt;.
This makes the guide more approachable and easier to read.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Everyone seems to agree that &lt;strong&gt;you should have an editor&lt;/strong&gt;.
In fact, Jacob Kaplan-Moss dedicated an entire article to this point [&lt;a href="#YNAE"&gt;JKM 3&lt;/a&gt;].
If you don&amp;#8217;t have access to an editor,
review your own work thrice then ask for someone else&amp;#8217;s review before publishing.
Try adjusting your margins to force the text to re-flow.
It&amp;#8217;s a very effective way to catch spelling or grammatical mistakes.&lt;/p&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_tools"&gt;Tools&lt;/h3&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;I&amp;#8217;ll start this section with a warning.
Tools often receive an undue amount of attention, especially from programmers.
With documentation, &lt;strong&gt;writing is the hard, important work&lt;/strong&gt;.
It&amp;#8217;s important to use good tools, but make sure you&amp;#8217;re not
&lt;a href="https://en.wikipedia.org/wiki/Law_of_triviality"&gt;bike shedding&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Your documentation should be stored in &lt;strong&gt;plain text and in version control&lt;/strong&gt;.
Most of your documentation is going to be written by programmers,
and programmers have powerful tools for manipulating text.
Using anything besides plain text is a frustration that makes it less
likely they&amp;#8217;ll enjoy writing documentation.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;You should have a &lt;strong&gt;process for reviewing changes&lt;/strong&gt; to the documentation.
Review will help maintain a consistent voice across your documentation
and will provide useful feedback to the writer.
Think of how useful code reviews are for improving your programming.
I&amp;#8217;d jump at the chance to get feedback from an expert writer.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;You &lt;strong&gt;should not use a wiki&lt;/strong&gt; for documentation.
Wikis make documentation "everyone&amp;#8217;s responsibility",
which really means it&amp;#8217;s nobody&amp;#8217;s responsibility.
Without this responsibility, wikis tend to decay into a web of assorted links without any sense of order or importance.
Wikis make it impossible to maintain a consistent voice throughout your documentation.
Finally, it&amp;#8217;s difficult to get review for your work before publishing.&lt;/p&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Recognize that automatically-generated documentation isn&amp;#8217;t a replacement for hand-crafted prose.
Remember that the bulk of your documentation should be tutorials meant to slowly ramp up your users to expert status.
Docstrings have very little utility in this process.&lt;/p&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_resources"&gt;Resources&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;Most of what I&amp;#8217;ve summarized here came from very few sources.
I highly recommend you read the following articles if you&amp;#8217;re interested in learning more:&lt;/p&gt;&lt;/div&gt;
&lt;div class="ulist"&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a id="SL"&gt;&lt;/a&gt; [TDT]: &lt;a href="http://stevelosh.com/blog/2013/09/teach-dont-tell/"&gt;Teach, Don&amp;#8217;t Tell&lt;/a&gt; (Steve Losh)
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a id="JKM 1"&gt;&lt;/a&gt; [JKM 1]: &lt;a href="https://jacobian.org/writing/what-to-write/"&gt;What to Write&lt;/a&gt; (Jacob Kaplan Moss)
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a id="JKM 2"&gt;&lt;/a&gt; [JKM 2]: &lt;a href="https://jacobian.org/writing/technical-style/"&gt;Technical Style&lt;/a&gt; (Jacob Kaplan Moss)
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a id="JKM 3"&gt;&lt;/a&gt; [JKM 3]: &lt;a href="https://jacobian.org/writing/editors/"&gt;You Need an Editor&lt;/a&gt; (Jacob Kaplan Moss)
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class="paragraph"&gt;&lt;p&gt;For later reference, I also reviewed these articles to form opinions about
general consensus outside of the primary sources above:&lt;/p&gt;&lt;/div&gt;
&lt;div class="ulist"&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="http://www.americanscientist.org/issues/id.877,y.0,no.,content.true,page.1,css.print/issue.aspx"&gt;The Science of Scientific Writing&lt;/a&gt;
  (George Gopen, Judith Swan): Good overview of how to structure a paper so
  readers find information where they expect it to be
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="http://www.writethedocs.org/"&gt;WriteTheDocs.org&lt;/a&gt;, specifically
  &lt;a href="http://www.writethedocs.org/guide/writing/beginners-guide-to-docs/"&gt;A Beginner&amp;#8217;s Guide to Writing Docs&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="https://github.com/noffle/art-of-readme"&gt;Art of README&lt;/a&gt;: An arguement for
  writing good READMEs and a template to help you get started
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="https://groups.google.com/forum/#!topic/scala-internals/r2GnzCFc3TY"&gt;Scala Documentation Discussion&lt;/a&gt;
  A discussion of why Scala&amp;#8217;s official documentation is so bad
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="http://r-pkgs.had.co.nz/vignettes.html"&gt;Vignettes&lt;/a&gt; (Hadley Wickham): Hadley
  is a rockstar in the R universe. This is an article from his style guide for
  writing R package documentation. This is the closest I could come to finding
  documentation advice for data products.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="http://steve-yegge.blogspot.com/2008/09/programmings-dirtiest-little-secret.html"&gt;Programming&amp;#8217;s Dirtiest Little Secret&lt;/a&gt;
  (Steve Yegge): Steve Yegge on why it&amp;#8217;s important to type well
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="https://byrslf.co/writing-great-documentation-44d90367115a#.nenvaqeng"&gt;Writing Great Documentation&lt;/a&gt;:
  This article comments on documentation&amp;#8217;s propensity towards kippleization.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href="https://www.gnu.org/prep/standards/standards.html#GNU-Manuals"&gt;GNU Manual Style Guide&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan Harter</dc:creator><pubDate>Fri, 03 Feb 2017 00:00:00 -0800</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2017-02-03:lit-review.html</guid><category>mozilla</category><category>documentation</category></item><item><title>Is moving to the Bay Area worth it?</title><link>http://blog.harterrt.com/is-moving-to-the-bay-area-worth-it.html</link><description>&lt;p&gt;I came across &lt;a href="http://blog.triplebyte.com/does-it-make-sense-for-programmers-to-move-to-the-bay-area"&gt;this article&lt;/a&gt; on the front page of Hacker News yesterday.
The author argues that Bay Area housing prices may be high, but the salary increase probably makes it worth while.
The author pulls together some interesting data to make their point,
but I have major &lt;strong&gt;issues with the analysis&lt;/strong&gt;.
In fact, the data seem to be &lt;strong&gt;showing the opposite trend&lt;/strong&gt;,&lt;/p&gt;
&lt;h2 id="summary-of-findings"&gt;Summary of findings&lt;/h2&gt;
&lt;p&gt;Here's the important information from the article:&lt;/p&gt;
&lt;p&gt;The author reviews median tech worker salaries from the BLS, Indeed, and GlassDoor and finds:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;engineers at top tech companies in the Bay Area stand to make between $15,000
and $33,000 more per year than engineers at top tech companies in Seattle.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Comparing median monthly rent from Zillow, the author finds:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;median rent is about $1400-$1500 a month (or roughly $17,000-$18,000 a year)
higher in the Bay Area than in the Seattle metro area&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The author then concludes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;higher Bay Area salaries at least cover the costs of higher rents.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="taxes"&gt;Taxes&lt;/h2&gt;
&lt;p&gt;The most obvious error is that this analysis completely &lt;strong&gt;ignores all taxes&lt;/strong&gt;.
I &lt;a href="https://news.ycombinator.com/item?id=13178880"&gt;pointed this out&lt;/a&gt; in the comments,
but the conversation exclusively focused on the difference between WA and CA state taxes.
I think it's important to note that this estimate also ignores &lt;em&gt;federal&lt;/em&gt; taxes as well.&lt;/p&gt;
&lt;p&gt;For example, consider a Seattle salary of $100k and a Bay Area salary of $133k.
Assuming a federal tax rate of 33%, that $33k tax difference will be reduced to $22k takehome.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$133k * (1-0.33) - $100 * (1-0.33) ~= $22k&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since WA does not have a state income tax and CA has a significant income tax,
you'll also end up paying just a bit over $10k in state taxes.
This drops the take home pay increase to $12k total.
And, according to the data, this is at the high end of the scale!&lt;/p&gt;
&lt;p&gt;In reality, there's no way we'll cover the $17k rent difference.&lt;/p&gt;
&lt;h2 id="median-rental-price"&gt;Median Rental Price&lt;/h2&gt;
&lt;p&gt;A few folks argued the use of a median isn't appropriate here.
I agree to a point, but I think it's probably a good first approximation,
especially since the author restricted their data to tech salaries in each market.&lt;/p&gt;
&lt;p&gt;However, I do have once concern here.
I'm willing to bet that &lt;strong&gt;Seattle renters can get more space for their median
rental than a Bay Area renter can get for the Bay Area median rental&lt;/strong&gt;.
As rent prices increase, renters will adjust by increasing the amount the spend
on rent and reducing the value of thier apartment.
In economic terms, a consumer's demand for an apartment is not perfectly inelastic.&lt;/p&gt;
&lt;p&gt;I saw this first hand when I moved to the Bay Area.
Prices were generally higher than what I was used to, so I adapted by increasing my
monthly rent, downsizing my apartment, and increasing my commute length.
I also noticed more of my peers sharing apartments or houses who wouldn't do so in lower COL areas.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;After accounting for taxes and reviewing the metrics used for rental costs, the
salary increase from moving to the Bay Area is &lt;strong&gt;very unlikely to cover the
increase in housing costs&lt;/strong&gt;, especially for similar housing.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Wed, 14 Dec 2016 00:00:00 -0800</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2016-12-14:is-moving-to-the-bay-area-worth-it.html</guid><category>critique</category></item><item><title>Announcing the Cross Sectional Dataset</title><link>http://blog.harterrt.com/announcing-the-cross-sectional-dataset.html</link><description>&lt;p&gt;I'm happy to announce a new telemetry dataset!&lt;/p&gt;
&lt;p&gt;The Cross Sectional dataset makes it easy to describe our users by providing
summary statistics for each client.  Like the Longitudinal table, there's one
row for each client_id in a 1% sample of clients.  However, the Cross Sectional
dataset simplifies your analysis by replacing the longitudinal arrays with
summary statistics.&lt;/p&gt;
&lt;p&gt;The dataset is now available in
&lt;a href="https://sql.telemetry.mozilla.org/queries/1669/source"&gt;STMO&lt;/a&gt;.  You can find
more information in &lt;a href="https://github.com/mozilla/telemetry-batch-view/blob/master/docs/choosing_a_dataset.md#cross-sectional"&gt;the
documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Take a look and let me know if you have any question or suggestions for new
columns!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Mon, 14 Nov 2016 00:00:00 -0800</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2016-11-14:announcing-the-cross-sectional-dataset.html</guid></item><item><title>Meta Documentation</title><link>http://blog.harterrt.com/meta-documentation.html</link><description>&lt;p&gt;You'll see a lot of posts coming down the line on documentation.&lt;/p&gt;
&lt;p&gt;We surveyed our customers last quarter and asked where our data pipeline was lacking.
It turns out the most painful part of using our data pipeline, is reading the documentation.
I've been interesting in learning how to write great documentation for a while,
so I volunteered to spend a significant amount of time reworking our documentation this quarter. &lt;/p&gt;
&lt;p&gt;To summarize, our team tries to make telemetry data useful.
Some of us build tools to make accessing the data easy,
others work on processing the data and making it available in an efficient and understandable format.
Last quarter I worked on the latter, pipelining hte data to make the format better.&lt;/p&gt;
&lt;p&gt;This year, I'll be working as a data ambassador.mentor,
going out to teams, identifying their data needs, and helping them reach their goals.&lt;/p&gt;
&lt;p&gt;Data is an incredibly useful tool.
It takes a lot of the guesswork out of building useful projects.
However, even though we have a great product, it's useless if our users don't understand how to use it.&lt;/p&gt;
&lt;p&gt;We have a great tool for our customers, but it's not worth the energy to learn about it. 
It's easier to do a one off analysis that is kind-of right.&lt;/p&gt;
&lt;p&gt;If you have a data product or tool without documentation, it's more likely than not that someone is misusing your data.
The hardest part of making data useful is understanding how it was collected and in what situations it is appropriate. &lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;&lt;/ul&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Thu, 03 Nov 2016 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2016-11-03:meta-documentation.html</guid><category>documentation mozilla</category></item><item><title>Why Markdown?</title><link>http://blog.harterrt.com/why-markdown.html</link><description>&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#better-process"&gt;Better Process&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#better-tools"&gt;Better Tools&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#one-less-tool"&gt;One less tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-documentation-sits-next-to-the-code"&gt;The documentation sits next to the code&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#syncronization"&gt;Syncronization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#discoverability"&gt;Discoverability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Last week I finished a &lt;a href="https://github.com/mozilla/telemetry-batch-view/pull/128"&gt;pull
request&lt;/a&gt; that moved
some documentation from &lt;a href="https://wiki.mozilla.org/Telemetry/LongitudinalExamples"&gt;mozilla's
wiki&lt;/a&gt; to a &lt;a href="https://github.com/mozilla/telemetry-batch-view/blob/master/docs/longitudinal_examples.md"&gt;github
repository&lt;/a&gt;.
It took a couple of hours of editing and toying with pandoc to get right, but
when I was done, I realized the benefits were difficult to see.  So, I decided
to write them out for posterity.&lt;/p&gt;
&lt;h2 id="better-process"&gt;Better Process&lt;/h2&gt;
&lt;p&gt;The only way to edit our wiki is through the web front end which causes some
major problems.&lt;/p&gt;
&lt;p&gt;For one, You're always editing the production version and there's no way to get
review before publishing. That's obviously not great.&lt;/p&gt;
&lt;p&gt;Second, your edits need to be submitted quickly - like within an hour, usually.
Since you're editing in a web form there's no good way to save your edits
locally.  Even worse, there's no good way to settle merge conflicts.&lt;/p&gt;
&lt;p&gt;With markdown, I can develop my revisions over the course of weeks and preview
them locally.  When it's time to publish I get review from my peers, which
makes my documentation more readable and helps me improve as an engineer.&lt;/p&gt;
&lt;h2 id="better-tools"&gt;Better Tools&lt;/h2&gt;
&lt;p&gt;I have powerful tools for manipulating text so using a simple web form to edit
technical documentation seems absurd to me.  With markdown, I get the joy of
using my favorite text editor in my favorite development environment&lt;/p&gt;
&lt;h3 id="one-less-tool"&gt;One less tool&lt;/h3&gt;
&lt;p&gt;Our team is already using Markdown for our README's and Github provides a much
better UX for revison control.  By moving to Markdown for our user facing
documentation, we have one less tool and syntax we need to depend on.&lt;/p&gt;
&lt;h2 id="the-documentation-sits-next-to-the-code"&gt;The documentation sits next to the code&lt;/h2&gt;
&lt;p&gt;Storing your documentation with your code has a lot of great benefits.&lt;/p&gt;
&lt;h3 id="syncronization"&gt;Syncronization&lt;/h3&gt;
&lt;p&gt;Pull requests can include simultanious changes to code and documentation, which
makes it more likely they'll stay in sync. Both because you don't need to go
edit them elsewhere and because it can become a review requirement.&lt;/p&gt;
&lt;h3 id="discoverability"&gt;Discoverability&lt;/h3&gt;
&lt;p&gt;Keeping the docs next to the code helps with discoverability. Your
code and your documentation should supplement each other. Keeping them close
together is only reasonable.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Thu, 03 Nov 2016 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2016-11-03:why-markdown.html</guid><category>documentation</category><category>mozilla</category></item><item><title>Working over SSH</title><link>http://blog.harterrt.com/working-over-ssh.html</link><description>&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tools"&gt;Tools&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#tmux"&gt;tmux&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#session-persistence"&gt;Session Persistence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#multiplexing"&gt;Multiplexing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#homeshick"&gt;Homeshick&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Working over SSH can be impossibly frustrating if you're not using the right tools. 
I promised my teammates a write-up how I work over ssh.
Using these tools will make it significantly easier / more fun to work with a remote linux system.&lt;/p&gt;
&lt;h2 id="tools"&gt;Tools&lt;/h2&gt;
&lt;h3 id="tmux"&gt;&lt;a href="https://tmux.github.io/"&gt;tmux&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For me, tmux is the single tool most important getting work done over SSH.
tmux does a lot of really cool things, but the most relevant feature to this discussion is session persistence.&lt;/p&gt;
&lt;h4 id="session-persistence"&gt;Session Persistence&lt;/h4&gt;
&lt;p&gt;tmux sessions can be detached and reattached at will.
That means you can &lt;strong&gt;execute some long running command on an AWS cluster, kill the ssh session, and the command will keep running&lt;/strong&gt;.
Later, you can reconnect to the cluster and session, it will be as if you hadn't left.
So much nicer than cussing out your flaky WiFi connection.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Start a new session named &amp;quot;foo&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# Opens a new shell as a subprocess&lt;/span&gt;
tmux new -s foo

&lt;span class="c1"&gt;# Do stuff ...&lt;/span&gt;
sleep 100

&lt;span class="c1"&gt;# Kill the session, returning you to the original shell&lt;/span&gt;
&lt;span class="c1"&gt;# with ctrl-b d&lt;/span&gt;

&lt;span class="c1"&gt;# Reconnect to the tmux session&lt;/span&gt;
tmux at -dt foo

&lt;span class="c1"&gt;# Still waiting!!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;More often, I use tmux just to save my place when I need to wrap up for the day.
Next morning, I can reattach my session and I'm already looking at the most relevant files for today's work.&lt;/p&gt;
&lt;h4 id="multiplexing"&gt;Multiplexing&lt;/h4&gt;
&lt;p&gt;This is what tmux's was built to do. I think persistence is just a nice side effect.
tmux allows you to open a bunch of terminals in a single ssh connection.
Think of tmux as a tiling window manager for the terminal.
Here's a screen shot of how I developed this blog post:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://blog.harterrt.com/images/example-tmux-session.png"&gt;&lt;/p&gt;
&lt;p&gt;That's all in one terminal window.
On the left I have a process serving up drafts of this document and on the right I have my text editor.
The extra context is indispensable when trying to figure out WTF is going on with a failing job.
For example, monitoring an &lt;code&gt;sbt ~test&lt;/code&gt; process on the left while making edits on the right.&lt;/p&gt;
&lt;h3 id="homeshick"&gt;&lt;a href="https://github.com/andsens/homeshick"&gt;Homeshick&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Configuring a new machine is a PITA.
For a while, I saw all configuration changes as a liability and refused to customize my environment.
After all, I'd eventually have to redo all of these configs when I get a new machine.
But, your tools should be a joy to use, and Homeshick makes this a non-issue.&lt;/p&gt;
&lt;p&gt;Homeshick pulls all of your dotfiles into a central git repository and handles linking these files to the right location.
Now, I can &lt;strong&gt;setup a new Ubuntu machine within ~5 minutes&lt;/strong&gt; with all of my dotfiles intact.
When I connect to a machine for the first time, I grab &lt;a href="https://github.com/harterrt/TIL/blob/master/linux/new-machine.md"&gt;this snippet&lt;/a&gt; and all of the initialization is done.
Even better, the meaningful config changes I make on my work machine magically materialize on my personal machine and VPS with a simple &lt;code&gt;git pull&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/andsens/homeshick"&gt;README&lt;/a&gt; is pretty good and it shouldn't take longer than ~15 minutes to set up.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Mon, 05 Sep 2016 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2016-09-05:working-over-ssh.html</guid><category>tools</category></item><item><title>Strange Spark Error</title><link>http://blog.harterrt.com/strange-spark-error.html</link><description>&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-bug"&gt;The Bug&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fixes"&gt;Fixes?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;I spend the better part of last week debugging a Spark error, so I figure it's worth writing up.&lt;/p&gt;
&lt;h1 id="the-bug"&gt;The Bug&lt;/h1&gt;
&lt;p&gt;I added the &lt;a href="https://github.com/harterrt/spark-failure/blob/master/failure.scala"&gt;this very simple view&lt;/a&gt; to our &lt;a href="https://github.com/mozilla/telemetry-batch-view/tree/master/src/main/scala/com/mozilla/telemetry/views"&gt;batch views repository&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;package&lt;/span&gt; &lt;span class="nn"&gt;com.mozilla.telemetry.views&lt;/span&gt;

&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.spark.&lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="nc"&gt;SparkConf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;SparkContext&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.spark.sql.hive.HiveContext&lt;/span&gt;

&lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Base&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;client_id&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;
&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Target&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;client_id&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;
&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;object&lt;/span&gt; &lt;span class="nc"&gt;FailingView&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="n"&gt;generateCrossSectional&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nc"&gt;Target&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;client_id&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Array&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;])&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Unit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;sparkConf&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;SparkConf&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="n"&gt;setAppName&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getName&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sparkConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setMaster&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sparkConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;spark.master&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;local[*]&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;SparkContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sparkConf&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;hiveContext&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;HiveContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hiveContext.implicits._&lt;/span&gt;

    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hiveContext&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SELECT * FROM longitudinal&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;selectExpr&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;client_id&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;generateCrossSectional&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When I run this on an ATMO cluster, I observe the following error:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;Exception in thread &amp;quot;main&amp;quot; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 1.0 failed 4 times, most recent failure: Lost task 24.3 in stage 1.0 (TID 64, ip-172-31-8-250.us-west-2.compute.internal): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.util.Utils&lt;/span&gt;&lt;span class="p"&gt;$.&lt;/span&gt;&lt;span class="nv"&gt;tryOrIOException&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;Utils.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;1222&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.TorrentBroadcast._value&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;lzycompute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;TorrentBroadcast.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.scheduler.Task.run(Task.scala:89)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.executor.Executor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;TaskRunner&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;Executor.scala&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;214&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;/span&gt;
&lt;span class="x"&gt;    at java.util.concurrent.ThreadPoolExecutor&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;Worker&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;ThreadPoolExecutor.java&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="m"&gt;615&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;    at java.lang.Thread.run(Thread.java:745)&lt;/span&gt;
&lt;span class="x"&gt;Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.TorrentBroadcast&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;anonfun&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;org&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;apache&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;spark&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;broadcast&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;TorrentBroadcast&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;readBlocks&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;1&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;anonfun&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;2.apply(TorrentBroadcast.scala:138)&lt;/span&gt;
&lt;span class="x"&gt;    at org.apache.spark.broadcast.TorrentBroadcast&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;anonfun&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;org&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;apache&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;spark&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;broadcast&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;TorrentBroadcast&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;readBlocks&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;1&lt;/span&gt;&lt;span class="p"&gt;$$&lt;/span&gt;&lt;span class="nv"&gt;anonfun&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="x"&gt;2.apply(TorrentBroadcast.scala:138)&lt;/span&gt;
&lt;span class="x"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I don't get much information from this message, and searching for this error yields a variety of threads with half solved solutions.
My hunch is this message pops up for a variety of issues.
What's even more strange is that this function runs successfully when we read local data using a SQLContext.&lt;/p&gt;
&lt;h1 id="fixes"&gt;Fixes?&lt;/h1&gt;
&lt;p&gt;I dug in for a while and I found two possible solutions.&lt;/p&gt;
&lt;p&gt;Instead of calling generateCrossSectional, we can just inline the meat of the function and everything works.
This isn't a great solution, because this function is going to grow over the next month and I don't want to maintain the behemoth. &lt;/p&gt;
&lt;p&gt;After a few refactors, I found that the function will run if I change the scope of the HiveContext val.
Take a look at &lt;a href="https://github.com/harterrt/spark-failure/blob/master/fixed.scala"&gt;this solution&lt;/a&gt;, which successfully runs.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;package&lt;/span&gt; &lt;span class="nn"&gt;com.mozilla.telemetry.views&lt;/span&gt;

&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.spark.&lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="nc"&gt;SparkConf&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;SparkContext&lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.spark.sql.hive.HiveContext&lt;/span&gt;

&lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Base&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;client_id&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;
&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Target&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;client_id&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;
&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;object&lt;/span&gt; &lt;span class="nc"&gt;PassingView&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="n"&gt;generateCrossSectional&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nc"&gt;Target&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;client_id&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Array&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;])&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Unit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;sparkConf&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;SparkConf&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="n"&gt;setAppName&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getClass&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getName&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sparkConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setMaster&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sparkConf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;spark.master&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;local[*]&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;SparkContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sparkConf&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;hiveContext&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;HiveContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hiveContext.implicits._&lt;/span&gt;

    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hiveContext&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SELECT * FROM longitudinal&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;selectExpr&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;client_id&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;Base&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;generateCrossSectional&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This solution isn't totally gratifying since I'm still unclear on what's causing the error, but I'm stopping here.
The cluster this was tested on is still running Spark 1.6, which apparently has some known issues.
Once we upgrade to 2.0 I may take another look.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan T. Harter</dc:creator><pubDate>Fri, 26 Aug 2016 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:blog.harterrt.com,2016-08-26:strange-spark-error.html</guid><category>spark</category><category>scala</category></item></channel></rss>