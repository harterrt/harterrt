<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="https://blog.harterrt.com/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="https://blog.harterrt.com/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="https://blog.harterrt.com/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Ryan T. Harter">
  <meta name="description" content="Posts and writings by Ryan T. Harter">

  <link href="https://blog.harterrt.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="blog.harterrt.com Atom" />
  <link href="https://blog.harterrt.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="blog.harterrt.com RSS" />

<meta name="keywords" content="spark, scala">

  <title>
    blog.harterrt.com
&ndash; Strange Spark Error  </title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-83638505-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="https://blog.harterrt.com">
        <img src="https://www.gravatar.com/avatar/8259d4073ed8ba5f61f5d60c978b0e69" alt="logo" class="round-img">
      </a>
      <h2><a href="https://blog.harterrt.com">Ryan T. Harter</a></h2>
      <p>Staff Data Engineer @ Mozilla</p>
      <ul>
        <li><a href="https://blog.harterrt.com/pages/about.html">About</a></li>
        <li><a href="https://github.com/harterrt/snippets" target="_blank">Work Snippets</a></li>
        <li><a href="resume.pdf" target="_blank">Resume</a></li>
        <li><a href="https://github.com/harterrt" target="_blank">Github</a></li>
        <li><a href="https://twitter.com/harterrt" target="_blank">Twitter</a></li>
        <li><a href="http://www.linkedin.com/pub/ryan-harter/11/a24/a21" target="_blank">LinkedIn</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <header>
      <p>
      <a href="https://blog.harterrt.com">Index</a> &brvbar; <a href="https://blog.harterrt.com/archives.html">Archives</a>
      &brvbar; <a href="https://blog.harterrt.com/feeds/all.atom.xml">Atom</a>
      &brvbar; <a href="https://blog.harterrt.com/feeds/all.rss.xml">RSS</a>
      </p>
    </header>

<article>
  <div class="article_title">
    <h1><a href="https://blog.harterrt.com/strange-spark-error.html">Strange Spark Error</a></h1>
  </div>
  <div class="article_text">
    <p>[TOC]</p>
<h1>Introduction</h1>
<p>I spend the better part of last week debugging a Spark error, so I figure it's worth writing up.</p>
<h1>The Bug</h1>
<p>I added the <a href="https://github.com/harterrt/spark-failure/blob/master/failure.scala">this very simple view</a> to our <a href="https://github.com/mozilla/telemetry-batch-view/tree/master/src/main/scala/com/mozilla/telemetry/views">batch views repository</a>.</p>
<div class="highlight"><pre><span></span><span class="k">package</span> <span class="nn">com.mozilla.telemetry.views</span>

<span class="k">import</span> <span class="nn">org.apache.spark.</span><span class="o">{</span><span class="nc">SparkConf</span><span class="o">,</span> <span class="nc">SparkContext</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.hive.HiveContext</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">Base</span> <span class="o">(</span>
    <span class="n">client_id</span><span class="k">:</span> <span class="kt">String</span>
<span class="o">)</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">Target</span> <span class="o">(</span>
    <span class="n">client_id</span><span class="k">:</span> <span class="kt">String</span>
<span class="o">)</span>

<span class="k">object</span> <span class="nc">FailingView</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">generateCrossSectional</span><span class="o">(</span><span class="n">base</span><span class="k">:</span> <span class="kt">Base</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nc">Target</span><span class="o">(</span><span class="n">base</span><span class="o">.</span><span class="n">client_id</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">sparkConf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setAppName</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="n">getClass</span><span class="o">.</span><span class="n">getName</span><span class="o">)</span>
    <span class="n">sparkConf</span><span class="o">.</span><span class="n">setMaster</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="s">&quot;spark.master&quot;</span><span class="o">,</span> <span class="s">&quot;local[*]&quot;</span><span class="o">))</span>
    <span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">hiveContext</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveContext</span><span class="o">(</span><span class="n">sc</span><span class="o">)</span>
    <span class="k">import</span> <span class="nn">hiveContext.implicits._</span>

    <span class="k">val</span> <span class="n">ds</span> <span class="k">=</span> <span class="n">hiveContext</span>
      <span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM longitudinal&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;client_id&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="n">as</span><span class="o">[</span><span class="kt">Base</span><span class="o">]</span>
    <span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">generateCrossSectional</span><span class="o">)</span>

    <span class="n">println</span><span class="o">(</span><span class="s">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span> <span class="o">+</span> <span class="n">output</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span> <span class="o">+</span> <span class="s">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>


<p>When I run this on an ATMO cluster, I observe the following error:</p>
<div class="highlight"><pre><span></span>Exception in thread &quot;main&quot; org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 1.0 failed 4 times, most recent failure: Lost task 24.3 in stage 1.0 (TID 64, ip-172-31-8-250.us-west-2.compute.internal): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
    at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1222)
    at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
    at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
    at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
    at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
    at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)
    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
    at org.apache.spark.scheduler.Task.run(Task.scala:89)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
    at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
    at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
...
</pre></div>


<p>I don't get much information from this message, and searching for this error yields a variety of threads with half solved solutions.
My hunch is this message pops up for a variety of issues.
What's even more strange is that this function runs successfully when we read local data using a SQLContext.</p>
<h1>Fixes?</h1>
<p>I dug in for a while and I found two possible solutions.</p>
<p>Instead of calling generateCrossSectional, we can just inline the meat of the function and everything works.
This isn't a great solution, because this function is going to grow over the next month and I don't want to maintain the behemoth. </p>
<p>After a few refactors, I found that the function will run if I change the scope of the HiveContext val.
Take a look at <a href="https://github.com/harterrt/spark-failure/blob/master/fixed.scala">this solution</a>, which successfully runs.</p>
<div class="highlight"><pre><span></span><span class="k">package</span> <span class="nn">com.mozilla.telemetry.views</span>

<span class="k">import</span> <span class="nn">org.apache.spark.</span><span class="o">{</span><span class="nc">SparkConf</span><span class="o">,</span> <span class="nc">SparkContext</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.hive.HiveContext</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">Base</span> <span class="o">(</span>
    <span class="n">client_id</span><span class="k">:</span> <span class="kt">String</span>
<span class="o">)</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">Target</span> <span class="o">(</span>
    <span class="n">client_id</span><span class="k">:</span> <span class="kt">String</span>
<span class="o">)</span>

<span class="k">object</span> <span class="nc">PassingView</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">generateCrossSectional</span><span class="o">(</span><span class="n">base</span><span class="k">:</span> <span class="kt">Base</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nc">Target</span><span class="o">(</span><span class="n">base</span><span class="o">.</span><span class="n">client_id</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">sparkConf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setAppName</span><span class="o">(</span><span class="k">this</span><span class="o">.</span><span class="n">getClass</span><span class="o">.</span><span class="n">getName</span><span class="o">)</span>
    <span class="n">sparkConf</span><span class="o">.</span><span class="n">setMaster</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="s">&quot;spark.master&quot;</span><span class="o">,</span> <span class="s">&quot;local[*]&quot;</span><span class="o">))</span>
    <span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">hiveContext</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HiveContext</span><span class="o">(</span><span class="n">sc</span><span class="o">)</span>
    <span class="k">import</span> <span class="nn">hiveContext.implicits._</span>

    <span class="k">val</span> <span class="n">ds</span> <span class="k">=</span> <span class="n">hiveContext</span>
      <span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM longitudinal&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;client_id&quot;</span><span class="o">)</span>
      <span class="o">.</span><span class="n">as</span><span class="o">[</span><span class="kt">Base</span><span class="o">]</span>
    <span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">generateCrossSectional</span><span class="o">)</span>

    <span class="n">println</span><span class="o">(</span><span class="s">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span> <span class="o">+</span> <span class="n">output</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span> <span class="o">+</span> <span class="s">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="o">)</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>


<h1>Conclusion</h1>
<p>This solution isn't totally gratifying since I'm still unclear on what's causing the error, but I'm stopping here.
The cluster this was tested on is still running Spark 1.6, which apparently has some known issues.
Once we upgrade to 2.0 I may take another look.</p>
  </div>
  <div class="article_meta">
    <p>Posted on: Fri 26 August 2016</p>
    <p>Category: <a href="https://blog.harterrt.com/category/mozilla.html">mozilla</a>
 &ndash; Tags:
      <a href="https://blog.harterrt.com/tag/spark.html">spark</a>,      <a href="https://blog.harterrt.com/tag/scala.html">scala</a>    </p>
  </div>
  <hr>
  <div class="article_footer">
    <p>
        Feel free to share any feedback via email!
        You can reach me at <code>harterrt</code> on gmail.
        Look forward to hearing from you!
    </p>
  </div>


</article>


    <div id="ending_message">
      <p>&copy; Ryan T. Harter. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. </p>
    </div>
  </main>
</body>
</html>